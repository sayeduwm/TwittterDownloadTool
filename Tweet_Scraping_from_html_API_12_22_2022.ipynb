{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17578f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "import time, re\n",
    "import csv\n",
    "import tweepy as tw\n",
    "from csv import writer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2037906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter Twitter API Keys\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "def urlRemover(txt):\n",
    "    import re\n",
    "    return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55cbe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapTweet(query):\n",
    "    driver = webdriver.Chrome('chromedriver')\n",
    "    driver.base_url = query\n",
    "    time.sleep(3)\n",
    "    driver.get(driver.base_url)\n",
    "    last_height=0\n",
    "    height=\"window.scrollTo(\"+str(last_height)+\",\"+str(last_height+2000)+\");\"\n",
    "    tweet_ID_list=[]\n",
    "    \n",
    "    while(True):\n",
    "        driver.execute_script(height)\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height=new_height\n",
    "        height=\"window.scrollTo(\"+str(new_height)+\",\"+str(new_height+2000)+\");\"\n",
    "        #print(last_height)\n",
    "        html_source = driver.page_source\n",
    "        sourcedata= html_source.encode('utf-8')\n",
    "        soup=bs(sourcedata)\n",
    "        tweets=soup.body.findAll([\"a\"])\n",
    "        for i in tweets:\n",
    "            if '/status/' in str(i):\n",
    "                clean_text= re.search('\"auto\" href=(.*) id=', str(i))\n",
    "                if clean_text:\n",
    "                    clean_text=clean_text.group(1).split('/')\n",
    "                    tweet_ID_list.append(clean_text[-1][:-1])\n",
    "                    print('row:',clean_text[-1][:-1])\n",
    "    driver.close()\n",
    "    return tweet_ID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exactword(bigram):\n",
    "    unibi=bigram.split(' ')\n",
    "    result='https://twitter.com/search?q=\"'+unibi[0]+\"%20\"+unibi[1]+'\"&src=typed_query&f=top'\n",
    "    return result\n",
    "\n",
    "def exactwordANyword(exactBigram,anywordList):\n",
    "    #\"construction zone\" (wisconsin, OR WI, OR chicago, OR milwaukee)\n",
    "    unibi=exactBigram.split(' ')\n",
    "    anylist='%20('\n",
    "    counter=0\n",
    "    length_anywordList=len(anywordList)\n",
    "    for i in (anywordList):       \n",
    "            \n",
    "        if counter<length_anywordList-1:\n",
    "            anylist=anylist+i+\"%2C%20OR%20\"\n",
    "           \n",
    "        else:\n",
    "            anylist=anylist+i+\")\"            \n",
    "        counter+=1\n",
    "    \n",
    "    result='https://twitter.com/search?q=\"'+unibi[0]+\"%20\"+unibi[1]+'\"'+anylist+'&src=typed_query&f=top'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('bigram_search_for_tweet _usstate.csv',usecols=['Bigrams'])# provide bigram keyword's csv file\n",
    "dfCity=pd.read_csv('usstate.csv',usecols=['state','name'])\n",
    "df.Bigrams.values[13:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ID_list_all=[]\n",
    "for i in df.Bigrams.values[20:]:    \n",
    "    for j,k in zip(dfCity.state.values,dfCity.name.values):        \n",
    "        query=exactwordANyword(i,[j,k])        \n",
    "        scrapTweet(query)\n",
    "        tweet_ID_list_all=tweet_ID_list_all+scrapTweet(query)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'tweetID':[(\"id\"+i) for i in tweet_ID_list_all]}).to_csv('tweetID_usstate.csv',index=None,mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetfromAPi(idlist): \n",
    "    c=0\n",
    "    lengthobsub=100\n",
    "    while lengthobsub>99:\n",
    "        #lengthobsub=len(tweet_ID_list_all[c:c+100])\n",
    "        tweetList=idlist[c:c+100]\n",
    "        #print(tweetList)\n",
    "        lengthobsub=len(tweetList)\n",
    "        c+=100\n",
    "        try:\n",
    "            tweets = api.statuses_lookup(tweetList,tweet_mode=\"extended\")\n",
    "            #print(tweets)\n",
    "            for tweet in tweets:\n",
    "                #print(tweet.created_at.date())\n",
    "                if tweet.place:\n",
    "                    place=[\"id\"+tweet.id_str,tweet.created_at.date(),tweet.place.full_name+\",\"+tweet.place.country,tweet.full_text]       \n",
    "                    pd.DataFrame(data=[place ]).to_csv('WZ.csv',mode='a',header=None,index=None)\n",
    "                else:\n",
    "                    place=[\"id\"+tweet.id_str,tweet.created_at.date(),\"None\",tweet.full_text]\n",
    "                    #print(place)\n",
    "                    pd.DataFrame(data=[place ]).to_csv('WZ.csv',mode='a',header=None,index=None)\n",
    "\n",
    "        except:      \n",
    "\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## it may return duplicate tweets, which need further processing to revome the duplicate tweets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
